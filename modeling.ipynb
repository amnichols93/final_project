{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib as plt\n",
    "import sklearn as skl\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our categorical variable list\n",
    "def cat_columns(df):\n",
    "    cats = df.dtypes[df.dtypes == \"object\"].index.tolist()\n",
    "    return cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical columns and merge with primary dataframe\n",
    "def encode_merge(df, cat_list):\n",
    "    for i in cat_list:\n",
    "        encode_df = pd.DataFrame(enc.fit_transform(df[i].values.reshape(-1,1)))\n",
    "        encode_df.columns = enc.get_feature_names([i])\n",
    "        df = df.merge(encode_df,left_index=True,right_index=True).drop(i,1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform/Scale/Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>Base_Team</th>\n",
       "      <th>Opp</th>\n",
       "      <th>Home</th>\n",
       "      <th>After_Bye</th>\n",
       "      <th>Wins Tally</th>\n",
       "      <th>PF Tally</th>\n",
       "      <th>PA Tally</th>\n",
       "      <th>OPassY Tally</th>\n",
       "      <th>ORushY Tally</th>\n",
       "      <th>...</th>\n",
       "      <th>TO_lost Tally</th>\n",
       "      <th>DPassY Tally</th>\n",
       "      <th>DRushY Tally</th>\n",
       "      <th>DTotYd Tally</th>\n",
       "      <th>TO_won Tally</th>\n",
       "      <th>Head_Coach</th>\n",
       "      <th>OC</th>\n",
       "      <th>DC</th>\n",
       "      <th>QB</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>49ers</td>\n",
       "      <td>Buccaneers</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kyle Shanahan</td>\n",
       "      <td>Kyle Shanahan</td>\n",
       "      <td>Robert Saleh</td>\n",
       "      <td>Jimmy Garoppolo</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>49ers</td>\n",
       "      <td>Bengals</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Kyle Shanahan</td>\n",
       "      <td>Kyle Shanahan</td>\n",
       "      <td>Robert Saleh</td>\n",
       "      <td>Jimmy Garoppolo</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>49ers</td>\n",
       "      <td>Steelers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Kyle Shanahan</td>\n",
       "      <td>Kyle Shanahan</td>\n",
       "      <td>Robert Saleh</td>\n",
       "      <td>Jimmy Garoppolo</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>49ers</td>\n",
       "      <td>Browns</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Kyle Shanahan</td>\n",
       "      <td>Kyle Shanahan</td>\n",
       "      <td>Robert Saleh</td>\n",
       "      <td>Jimmy Garoppolo</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>49ers</td>\n",
       "      <td>Rams</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>909.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Kyle Shanahan</td>\n",
       "      <td>Kyle Shanahan</td>\n",
       "      <td>Robert Saleh</td>\n",
       "      <td>Jimmy Garoppolo</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5115</th>\n",
       "      <td>13</td>\n",
       "      <td>Titans</td>\n",
       "      <td>Jaguars</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2745.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>3968.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Jeff Fisher</td>\n",
       "      <td>Mike Heimerdinger</td>\n",
       "      <td>Chuck Cecil</td>\n",
       "      <td>Vince Young</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>14</td>\n",
       "      <td>Titans</td>\n",
       "      <td>Colts</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>2148.0</td>\n",
       "      <td>1351.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2864.0</td>\n",
       "      <td>1481.0</td>\n",
       "      <td>4345.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Jeff Fisher</td>\n",
       "      <td>Mike Heimerdinger</td>\n",
       "      <td>Chuck Cecil</td>\n",
       "      <td>Vince Young</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>15</td>\n",
       "      <td>Titans</td>\n",
       "      <td>Texans</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>2392.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3176.0</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>4744.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Jeff Fisher</td>\n",
       "      <td>Mike Heimerdinger</td>\n",
       "      <td>Chuck Cecil</td>\n",
       "      <td>Vince Young</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>16</td>\n",
       "      <td>Titans</td>\n",
       "      <td>Chiefs</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>2604.0</td>\n",
       "      <td>1619.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3469.0</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>5067.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Jeff Fisher</td>\n",
       "      <td>Mike Heimerdinger</td>\n",
       "      <td>Chuck Cecil</td>\n",
       "      <td>Vince Young</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5119</th>\n",
       "      <td>17</td>\n",
       "      <td>Titans</td>\n",
       "      <td>Colts</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>2817.0</td>\n",
       "      <td>1676.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>5525.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Jeff Fisher</td>\n",
       "      <td>Mike Heimerdinger</td>\n",
       "      <td>Chuck Cecil</td>\n",
       "      <td>Vince Young</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5120 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Week Base_Team         Opp  Home  After_Bye  Wins Tally  PF Tally  \\\n",
       "0        1     49ers  Buccaneers   0.0          0         0.0       0.0   \n",
       "1        2     49ers     Bengals   0.0          0         1.0      31.0   \n",
       "2        3     49ers    Steelers   1.0          0         2.0      72.0   \n",
       "3        5     49ers      Browns   1.0          1         3.0      96.0   \n",
       "4        6     49ers        Rams   0.0          0         4.0     127.0   \n",
       "...    ...       ...         ...   ...        ...         ...       ...   \n",
       "5115    13    Titans     Jaguars   1.0          0         5.0     257.0   \n",
       "5116    14    Titans       Colts   1.0          0         5.0     263.0   \n",
       "5117    15    Titans      Texans   1.0          0         5.0     291.0   \n",
       "5118    16    Titans      Chiefs   0.0          0         6.0     322.0   \n",
       "5119    17    Titans       Colts   0.0          0         6.0     336.0   \n",
       "\n",
       "      PA Tally  OPassY Tally  ORushY Tally  ...  TO_lost Tally  DPassY Tally  \\\n",
       "0          0.0           0.0           0.0  ...            0.0           0.0   \n",
       "1         17.0         158.0          98.0  ...            2.0         174.0   \n",
       "2         34.0         470.0         357.0  ...            3.0         465.0   \n",
       "3         54.0         738.0         525.0  ...            8.0         625.0   \n",
       "4         57.0         909.0         800.0  ...            8.0         703.0   \n",
       "...        ...           ...           ...  ...            ...           ...   \n",
       "5115     218.0        1985.0        1294.0  ...           21.0        2745.0   \n",
       "5116     235.0        2148.0        1351.0  ...           23.0        2864.0   \n",
       "5117     265.0        2392.0        1472.0  ...           25.0        3176.0   \n",
       "5118     282.0        2604.0        1619.0  ...           26.0        3469.0   \n",
       "5119     316.0        2817.0        1676.0  ...           28.0        3775.0   \n",
       "\n",
       "      DRushY Tally  DTotYd Tally  TO_won Tally     Head_Coach  \\\n",
       "0              0.0           0.0           0.0  Kyle Shanahan   \n",
       "1            121.0         295.0           4.0  Kyle Shanahan   \n",
       "2            146.0         611.0           5.0  Kyle Shanahan   \n",
       "3            225.0         850.0           7.0  Kyle Shanahan   \n",
       "4            327.0        1030.0          11.0  Kyle Shanahan   \n",
       "...            ...           ...           ...            ...   \n",
       "5115        1223.0        3968.0          21.0    Jeff Fisher   \n",
       "5116        1481.0        4345.0          21.0    Jeff Fisher   \n",
       "5117        1568.0        4744.0          21.0    Jeff Fisher   \n",
       "5118        1598.0        5067.0          22.0    Jeff Fisher   \n",
       "5119        1750.0        5525.0          24.0    Jeff Fisher   \n",
       "\n",
       "                     OC            DC               QB Results  \n",
       "0         Kyle Shanahan  Robert Saleh  Jimmy Garoppolo     1.0  \n",
       "1         Kyle Shanahan  Robert Saleh  Jimmy Garoppolo     1.0  \n",
       "2         Kyle Shanahan  Robert Saleh  Jimmy Garoppolo     1.0  \n",
       "3         Kyle Shanahan  Robert Saleh  Jimmy Garoppolo     1.0  \n",
       "4         Kyle Shanahan  Robert Saleh  Jimmy Garoppolo     1.0  \n",
       "...                 ...           ...              ...     ...  \n",
       "5115  Mike Heimerdinger   Chuck Cecil      Vince Young     0.0  \n",
       "5116  Mike Heimerdinger   Chuck Cecil      Vince Young     0.0  \n",
       "5117  Mike Heimerdinger   Chuck Cecil      Vince Young     1.0  \n",
       "5118  Mike Heimerdinger   Chuck Cecil      Vince Young     0.0  \n",
       "5119  Mike Heimerdinger   Chuck Cecil      Vince Young     0.0  \n",
       "\n",
       "[5120 rows x 21 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allteam_df = pd.read_csv('Resources/allteam_csvs/allteam_df.csv')\n",
    "allteam_df = allteam_df.drop(columns='Unnamed: 0')\n",
    "allteam_df = allteam_df.drop(columns=['Year', \"Day\"])\n",
    "allteam_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = encode_merge(allteam_df, cat_list=cat_columns(allteam_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Week',\n",
       " 'Home',\n",
       " 'After_Bye',\n",
       " 'Wins Tally',\n",
       " 'PF Tally',\n",
       " 'PA Tally',\n",
       " 'OPassY Tally',\n",
       " 'ORushY Tally',\n",
       " 'OTotYd Tally',\n",
       " 'TO_lost Tally',\n",
       " 'DPassY Tally',\n",
       " 'DRushY Tally',\n",
       " 'DTotYd Tally',\n",
       " 'TO_won Tally',\n",
       " 'Results',\n",
       " 'Base_Team_49ers',\n",
       " 'Base_Team_Bears',\n",
       " 'Base_Team_Bengals',\n",
       " 'Base_Team_Bills',\n",
       " 'Base_Team_Broncos',\n",
       " 'Base_Team_Browns',\n",
       " 'Base_Team_Buccaneers',\n",
       " 'Base_Team_Cardinals',\n",
       " 'Base_Team_Chargers',\n",
       " 'Base_Team_Chiefs',\n",
       " 'Base_Team_Colts',\n",
       " 'Base_Team_Cowboys',\n",
       " 'Base_Team_Dolphins',\n",
       " 'Base_Team_Eagles',\n",
       " 'Base_Team_Falcons',\n",
       " 'Base_Team_Giants',\n",
       " 'Base_Team_Jaguars',\n",
       " 'Base_Team_Jets',\n",
       " 'Base_Team_Lions',\n",
       " 'Base_Team_Packers',\n",
       " 'Base_Team_Panthers',\n",
       " 'Base_Team_Patriots',\n",
       " 'Base_Team_Raiders',\n",
       " 'Base_Team_Rams',\n",
       " 'Base_Team_Ravens',\n",
       " 'Base_Team_Saints',\n",
       " 'Base_Team_Seahawks',\n",
       " 'Base_Team_Steelers',\n",
       " 'Base_Team_Texans',\n",
       " 'Base_Team_Titans',\n",
       " 'Base_Team_Vikings',\n",
       " 'Base_Team_Washington',\n",
       " 'Opp_49ers',\n",
       " 'Opp_Bears',\n",
       " 'Opp_Bengals',\n",
       " 'Opp_Bills',\n",
       " 'Opp_Broncos',\n",
       " 'Opp_Browns',\n",
       " 'Opp_Buccaneers',\n",
       " 'Opp_Cardinals',\n",
       " 'Opp_Chargers',\n",
       " 'Opp_Chiefs',\n",
       " 'Opp_Colts',\n",
       " 'Opp_Cowboys',\n",
       " 'Opp_Dolphins',\n",
       " 'Opp_Eagles',\n",
       " 'Opp_Falcons',\n",
       " 'Opp_Giants',\n",
       " 'Opp_Jaguars',\n",
       " 'Opp_Jets',\n",
       " 'Opp_Lions',\n",
       " 'Opp_Packers',\n",
       " 'Opp_Panthers',\n",
       " 'Opp_Patriots',\n",
       " 'Opp_Raiders',\n",
       " 'Opp_Rams',\n",
       " 'Opp_Ravens',\n",
       " 'Opp_Saints',\n",
       " 'Opp_Seahawks',\n",
       " 'Opp_Steelers',\n",
       " 'Opp_Texans',\n",
       " 'Opp_Titans',\n",
       " 'Opp_Vikings',\n",
       " 'Opp_Washington',\n",
       " 'Head_Coach_Aaron Kromer',\n",
       " 'Head_Coach_Adam Gase',\n",
       " 'Head_Coach_Andy Reid',\n",
       " 'Head_Coach_Anthony Lynn',\n",
       " 'Head_Coach_Ben McAdoo',\n",
       " 'Head_Coach_Bill Belichick',\n",
       " \"Head_Coach_Bill O'Brien\",\n",
       " 'Head_Coach_Brad Childress',\n",
       " 'Head_Coach_Brian Flores',\n",
       " 'Head_Coach_Bruce Arians',\n",
       " 'Head_Coach_Chan Gailey',\n",
       " 'Head_Coach_Chip Kelly',\n",
       " 'Head_Coach_Chuck Pagano',\n",
       " 'Head_Coach_Dan Quinn',\n",
       " 'Head_Coach_Dennis Allen',\n",
       " 'Head_Coach_Dirk Koetter',\n",
       " 'Head_Coach_Doug Marrone',\n",
       " 'Head_Coach_Doug Pederson',\n",
       " 'Head_Coach_Eric Mangini',\n",
       " 'Head_Coach_Frank Reich',\n",
       " 'Head_Coach_Freddie Kitchens',\n",
       " 'Head_Coach_Gary Kubiak',\n",
       " 'Head_Coach_Greg Schiano',\n",
       " 'Head_Coach_Gus Bradley',\n",
       " 'Head_Coach_Hue Jackson',\n",
       " 'Head_Coach_Jack Del Rio',\n",
       " 'Head_Coach_Jason Garrett',\n",
       " 'Head_Coach_Jay Gruden',\n",
       " 'Head_Coach_Jeff Fisher',\n",
       " 'Head_Coach_Jim Caldwell',\n",
       " 'Head_Coach_Jim Harbaugh',\n",
       " 'Head_Coach_Jim Schwartz',\n",
       " 'Head_Coach_Jim Tomsula',\n",
       " 'Head_Coach_Joe Philbin',\n",
       " 'Head_Coach_John Fox',\n",
       " 'Head_Coach_John Harbaugh',\n",
       " 'Head_Coach_Jon Gruden',\n",
       " 'Head_Coach_Josh McDaniels',\n",
       " 'Head_Coach_Ken Whisenhunt',\n",
       " 'Head_Coach_Kliff Kingsbury',\n",
       " 'Head_Coach_Kyle Shanahan',\n",
       " 'Head_Coach_Leslie Frazier',\n",
       " 'Head_Coach_Lovie Smith',\n",
       " 'Head_Coach_Marc Trestman',\n",
       " 'Head_Coach_Marvin Lewis',\n",
       " 'Head_Coach_Matt LaFleur',\n",
       " 'Head_Coach_Matt Nagy',\n",
       " 'Head_Coach_Matt Patricia',\n",
       " 'Head_Coach_Mike McCarthy',\n",
       " 'Head_Coach_Mike McCoy',\n",
       " 'Head_Coach_Mike Mularkey',\n",
       " 'Head_Coach_Mike Munchak',\n",
       " 'Head_Coach_Mike Pettine',\n",
       " 'Head_Coach_Mike Priefer',\n",
       " 'Head_Coach_Mike Shanahan',\n",
       " 'Head_Coach_Mike Singletary',\n",
       " 'Head_Coach_Mike Smith',\n",
       " 'Head_Coach_Mike Tomlin',\n",
       " 'Head_Coach_Mike Vrabel',\n",
       " 'Head_Coach_Mike Zimmer',\n",
       " 'Head_Coach_Norv Turner',\n",
       " 'Head_Coach_Pat Shurmur',\n",
       " 'Head_Coach_Pete Carroll',\n",
       " 'Head_Coach_Raheem Morris',\n",
       " 'Head_Coach_Rex Ryan',\n",
       " 'Head_Coach_Rob Chudzinski',\n",
       " 'Head_Coach_Romeo Crennel',\n",
       " 'Head_Coach_Ron Rivera',\n",
       " 'Head_Coach_Sean McDermott',\n",
       " 'Head_Coach_Sean McVay',\n",
       " 'Head_Coach_Sean Payton',\n",
       " 'Head_Coach_Steve Spagnuolo',\n",
       " 'Head_Coach_Steve Wilks',\n",
       " 'Head_Coach_Todd Bowles',\n",
       " 'Head_Coach_Todd Haley',\n",
       " 'Head_Coach_Tom Cable',\n",
       " 'Head_Coach_Tom Coughlin',\n",
       " 'Head_Coach_Tony Sparano',\n",
       " 'Head_Coach_Vance Joseph',\n",
       " 'Head_Coach_Vic Fangio',\n",
       " 'Head_Coach_Zac Taylor',\n",
       " 'OC_Aaron Kromer',\n",
       " 'OC_Adam Gase',\n",
       " 'OC_Al Saunders',\n",
       " 'OC_Arthur Smith',\n",
       " 'OC_Ben McAdoo',\n",
       " 'OC_Bill Belichick',\n",
       " 'OC_Bill Callahan',\n",
       " 'OC_Bill Lazor',\n",
       " 'OC_Bill Muir',\n",
       " 'OC_Bill Musgrave',\n",
       " \"OC_Bill O'Brien\",\n",
       " 'OC_Bob Bratkowski',\n",
       " 'OC_Brad Childress',\n",
       " 'OC_Brian Callahan',\n",
       " 'OC_Brian Daboll',\n",
       " 'OC_Brian Schottenheimer',\n",
       " 'OC_Bruce Arians',\n",
       " 'OC_Byron Leftwich',\n",
       " 'OC_Cam Cameron',\n",
       " \"OC_Chad O'Shea\",\n",
       " 'OC_Chan Gailey',\n",
       " 'OC_Charlie Weis',\n",
       " 'OC_Chris Palmer',\n",
       " 'OC_Clarence Shelmon',\n",
       " 'OC_Clyde Christensen',\n",
       " 'OC_Curtis Modkins',\n",
       " 'OC_Dan Henning',\n",
       " 'OC_Darrell Bevell',\n",
       " 'OC_Dirk Koetter',\n",
       " 'OC_Doug Pederson',\n",
       " 'OC_Dowell Loggains',\n",
       " 'OC_Edgar Bennett',\n",
       " 'OC_Eric Bieniemy',\n",
       " 'OC_Frank Reich',\n",
       " 'OC_Gary Kubiak',\n",
       " 'OC_Geep Chryst',\n",
       " 'OC_George Godsey',\n",
       " 'OC_Greg Knapp',\n",
       " 'OC_Greg Olson',\n",
       " 'OC_Greg Roman',\n",
       " 'OC_Hal Hunter',\n",
       " 'OC_Harold Goodwin',\n",
       " 'OC_Hue Jackson',\n",
       " 'OC_Jason Garrett',\n",
       " 'OC_Jason Michael',\n",
       " 'OC_Jay Gruden',\n",
       " 'OC_Jedd Fisch',\n",
       " 'OC_Jeff Davidson',\n",
       " 'OC_Jeff Tedford',\n",
       " 'OC_Jeremy Bates',\n",
       " 'OC_Jim Bob Cooter',\n",
       " 'OC_Jim Caldwell',\n",
       " 'OC_Jimmy Raye',\n",
       " 'OC_Joe Lombardi',\n",
       " 'OC_Joe Philbin',\n",
       " 'OC_John DeFilippo',\n",
       " 'OC_John Morton',\n",
       " 'OC_Josh McDaniels',\n",
       " 'OC_Kellen Moore',\n",
       " 'OC_Ken Whisenhunt',\n",
       " 'OC_Ken Zampese',\n",
       " 'OC_Kevin Gilbride',\n",
       " \"OC_Kevin O'Connell\",\n",
       " 'OC_Kevin Stefanski',\n",
       " 'OC_Kliff Kingsbury',\n",
       " 'OC_Kyle Shanahan',\n",
       " 'OC_Marc Trestman',\n",
       " 'OC_Mark Helfrich',\n",
       " 'OC_Marty Mornhinweg',\n",
       " 'OC_Matt Cavanaugh',\n",
       " 'OC_Matt LaFleur',\n",
       " 'OC_Matt Nagy',\n",
       " 'OC_Mike Groh',\n",
       " 'OC_Mike Heimerdinger',\n",
       " 'OC_Mike Martz',\n",
       " 'OC_Mike McCoy',\n",
       " 'OC_Mike Miller',\n",
       " 'OC_Mike Mularkey',\n",
       " 'OC_Mike Sherman',\n",
       " 'OC_Mike Shula',\n",
       " 'OC_Mike Sullivan',\n",
       " 'OC_Mike Tice',\n",
       " 'OC_Nathaniel Hackett',\n",
       " 'OC_Nick Sirianni',\n",
       " 'OC_Norv Turner',\n",
       " 'OC_Pat Shurmur',\n",
       " 'OC_Pep Hamilton',\n",
       " 'OC_Pete Carmichael',\n",
       " 'OC_Randy Fichtner',\n",
       " 'OC_Rich Scangarello',\n",
       " 'OC_Rick Dennison',\n",
       " 'OC_Rob Boras',\n",
       " 'OC_Rob Chudzinski',\n",
       " 'OC_Scott Linehan',\n",
       " 'OC_Sean McVay',\n",
       " 'OC_Steve Sarkisian',\n",
       " 'OC_Terry Robiskie',\n",
       " 'OC_Tim Kelly',\n",
       " 'OC_Todd Downing',\n",
       " 'OC_Todd Haley',\n",
       " 'OC_Todd Monken',\n",
       " 'OC_Tom Clements',\n",
       " 'OC_Tony Sparano',\n",
       " 'DC_Al Holcomb',\n",
       " 'DC_Alan Williams',\n",
       " 'DC_Bill Belichick',\n",
       " 'DC_Bill Davis',\n",
       " 'DC_Bill Sheridan',\n",
       " 'DC_Bob Babich',\n",
       " 'DC_Bob Sutton',\n",
       " 'DC_Brian VanGorder',\n",
       " 'DC_Chuck Bresnahan',\n",
       " 'DC_Chuck Cecil',\n",
       " 'DC_Chuck Pagano',\n",
       " 'DC_Dan Quinn',\n",
       " 'DC_Dave Wannstedt',\n",
       " 'DC_Dean Pees',\n",
       " 'DC_Dennis Allen',\n",
       " 'DC_Dennis Thurman',\n",
       " 'DC_Dick Jauron',\n",
       " 'DC_Dick LeBeau',\n",
       " 'DC_Dom Capers',\n",
       " 'DC_Don Martindale',\n",
       " 'DC_Ed Donatell',\n",
       " 'DC_Eric Mangini',\n",
       " 'DC_Eric Washington',\n",
       " 'DC_Frank Bush',\n",
       " 'DC_Fred Pagac',\n",
       " 'DC_George Edwards',\n",
       " 'DC_Greg Manusky',\n",
       " 'DC_Greg Mattison',\n",
       " 'DC_Gregg Williams',\n",
       " 'DC_Gunther Cunningham',\n",
       " 'DC_Gus Bradley',\n",
       " 'DC_Jack Del Rio',\n",
       " 'DC_James Bettcher',\n",
       " 'DC_Jason Tarver',\n",
       " 'DC_Jeff Fisher',\n",
       " 'DC_Jerry Gray',\n",
       " 'DC_Jim Bob Cooter',\n",
       " 'DC_Jim Haslett',\n",
       " \"DC_Jim O'Neil\",\n",
       " 'DC_Jim Schwartz',\n",
       " 'DC_Joe Barry',\n",
       " 'DC_Joe Woods',\n",
       " 'DC_John Marshall',\n",
       " 'DC_John Pagano',\n",
       " 'DC_Juan Castillo',\n",
       " 'DC_Kacy Rodgers',\n",
       " 'DC_Keith Butler',\n",
       " 'DC_Keith Millard',\n",
       " 'DC_Ken Flajole',\n",
       " 'DC_Ken Norton',\n",
       " 'DC_Kevin Coyle',\n",
       " 'DC_Kris Richard',\n",
       " 'DC_Larry Coyer',\n",
       " 'DC_Leslie Frazier',\n",
       " 'DC_Lou Anarumo',\n",
       " 'DC_Marquand Manuel',\n",
       " 'DC_Matt Burke',\n",
       " 'DC_Matt Eberflus',\n",
       " 'DC_Matt Patricia',\n",
       " 'DC_Mel Tucker',\n",
       " 'DC_Mike Nolan',\n",
       " 'DC_Mike Pettine',\n",
       " 'DC_Mike Smith',\n",
       " 'DC_Mike Vrabel',\n",
       " 'DC_Mike Zimmer',\n",
       " 'DC_Monte Kiffin',\n",
       " 'DC_Patrick Graham',\n",
       " 'DC_Paul Guenther',\n",
       " 'DC_Paul Pasqualoni',\n",
       " 'DC_Perry Fewell',\n",
       " 'DC_Raheem Morris',\n",
       " 'DC_Ray Horton',\n",
       " 'DC_Richard Smith',\n",
       " 'DC_Rob Ryan',\n",
       " 'DC_Robert Saleh',\n",
       " 'DC_Rod Marinelli',\n",
       " 'DC_Romeo Crennel',\n",
       " 'DC_Ron Meeks',\n",
       " 'DC_Ron Rivera',\n",
       " 'DC_Sean McDermott',\n",
       " 'DC_Steve Spagnuolo',\n",
       " 'DC_Steve Wilks',\n",
       " 'DC_Ted Monachino',\n",
       " 'DC_Teryl Austin',\n",
       " 'DC_Tim Walton',\n",
       " 'DC_Todd Bowles',\n",
       " 'DC_Todd Wash',\n",
       " 'DC_Vance Joseph',\n",
       " 'DC_Vic Fangio',\n",
       " 'DC_Wade Phillips',\n",
       " 'QB_Aaron Rodgers',\n",
       " 'QB_Alex Smith',\n",
       " 'QB_Andrew Luck',\n",
       " 'QB_Andy Dalton',\n",
       " 'QB_Baker Mayfield',\n",
       " 'QB_Ben Roethlisberger',\n",
       " 'QB_Blaine Gabbert',\n",
       " 'QB_Blake Bortles',\n",
       " 'QB_Brandon Weeden',\n",
       " 'QB_Brett Favre',\n",
       " 'QB_Brett Hundley',\n",
       " 'QB_Brian Hoyer',\n",
       " 'QB_Brock Osweiler',\n",
       " 'QB_Cam Newton',\n",
       " 'QB_Carson Palmer',\n",
       " 'QB_Carson Wentz',\n",
       " 'QB_Case Keenum',\n",
       " 'QB_Chad Henne',\n",
       " 'QB_Christian Ponder',\n",
       " 'QB_Cody Kessler',\n",
       " 'QB_Colin Kaepernick',\n",
       " 'QB_Colt McCoy',\n",
       " 'QB_Curtis Painter',\n",
       " 'QB_Dak Prescott',\n",
       " 'QB_Daniel Jones',\n",
       " 'QB_David Garrard',\n",
       " 'QB_DeShone Kizer',\n",
       " 'QB_Derek Anderson',\n",
       " 'QB_Derek Carr',\n",
       " 'QB_Deshaun Watson',\n",
       " 'QB_Donovan McNabb',\n",
       " 'QB_Drew Brees',\n",
       " 'QB_Drew Stanton',\n",
       " 'QB_EJ Manuel',\n",
       " 'QB_Eli Manning',\n",
       " 'QB_Gardner Minshew',\n",
       " 'QB_Geno Smith',\n",
       " 'QB_Jacoby Brissett',\n",
       " 'QB_Jake Delhomme',\n",
       " 'QB_Jake Locker',\n",
       " 'QB_Jameis Winston',\n",
       " 'QB_Jared Goff',\n",
       " 'QB_Jason Campbell',\n",
       " 'QB_Jay Cutler',\n",
       " 'QB_Jimmy Clausen',\n",
       " 'QB_Jimmy Garoppolo',\n",
       " 'QB_Joe Flacco',\n",
       " 'QB_John Skelton',\n",
       " 'QB_Jon Kitna',\n",
       " 'QB_Josh Allen',\n",
       " 'QB_Josh Freeman',\n",
       " 'QB_Josh McCown',\n",
       " 'QB_Josh Rosen',\n",
       " 'QB_Kevin Kolb',\n",
       " 'QB_Kirk Cousins',\n",
       " 'QB_Kyle Allen',\n",
       " 'QB_Kyle Orton',\n",
       " 'QB_Kyler Murray',\n",
       " 'QB_Lamar Jackson',\n",
       " 'QB_Marcus Mariota',\n",
       " 'QB_Mark Sanchez',\n",
       " 'QB_Mason Rudolph',\n",
       " 'QB_Matt Cassel',\n",
       " 'QB_Matt Hasselbeck',\n",
       " 'QB_Matt Ryan',\n",
       " 'QB_Matt Schaub',\n",
       " 'QB_Matthew Stafford',\n",
       " 'QB_Michael Vick',\n",
       " 'QB_Mike Glennon',\n",
       " 'QB_Mitchell Trubisky',\n",
       " 'QB_Nick Foles',\n",
       " 'QB_Other',\n",
       " 'QB_Patrick Mahomes',\n",
       " 'QB_Peyton Manning',\n",
       " 'QB_Philip Rivers',\n",
       " 'QB_Rex Grossman',\n",
       " 'QB_Robert Griffin III',\n",
       " 'QB_Russell Wilson',\n",
       " 'QB_Ryan Fitzpatrick',\n",
       " 'QB_Ryan Tannehill',\n",
       " 'QB_Sam Bradford',\n",
       " 'QB_Sam Darnold',\n",
       " 'QB_Shaun Hill',\n",
       " 'QB_Tarvaris Jackson',\n",
       " 'QB_Teddy Bridgewater',\n",
       " 'QB_Terrelle Pryor',\n",
       " 'QB_Tim Tebow',\n",
       " 'QB_Tom Brady',\n",
       " 'QB_Tom Savage',\n",
       " 'QB_Tony Romo',\n",
       " 'QB_Trevor Siemian',\n",
       " 'QB_Tyrod Taylor',\n",
       " 'QB_Vince Young',\n",
       " 'QB_Zach Mettenberger']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(encoded_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(encoded_df)\n",
    "scaled_data = scaler.transform(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wins Tally</th>\n",
       "      <th>PF Tally</th>\n",
       "      <th>PA Tally</th>\n",
       "      <th>OPassY Tally</th>\n",
       "      <th>ORushY Tally</th>\n",
       "      <th>OTotYd Tally</th>\n",
       "      <th>TO_lost Tally</th>\n",
       "      <th>DPassY Tally</th>\n",
       "      <th>DRushY Tally</th>\n",
       "      <th>DTotYd Tally</th>\n",
       "      <th>...</th>\n",
       "      <th>QB_Tom Savage</th>\n",
       "      <th>QB_Tony Romo</th>\n",
       "      <th>QB_Trevor Siemian</th>\n",
       "      <th>QB_Tyrod Taylor</th>\n",
       "      <th>QB_Vince Young</th>\n",
       "      <th>QB_Zach Mettenberger</th>\n",
       "      <th>Results</th>\n",
       "      <th>Week</th>\n",
       "      <th>Home</th>\n",
       "      <th>After_Bye</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.273555</td>\n",
       "      <td>-1.515705</td>\n",
       "      <td>-1.544165</td>\n",
       "      <td>-1.571823</td>\n",
       "      <td>-1.498599</td>\n",
       "      <td>-1.595272</td>\n",
       "      <td>-1.415325</td>\n",
       "      <td>-1.601472</td>\n",
       "      <td>-1.523287</td>\n",
       "      <td>-1.602728</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055989</td>\n",
       "      <td>-0.110715</td>\n",
       "      <td>-0.074154</td>\n",
       "      <td>-0.094165</td>\n",
       "      <td>-0.052363</td>\n",
       "      <td>-0.054206</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.933444</td>\n",
       "      <td>-1.240405</td>\n",
       "      <td>-1.390180</td>\n",
       "      <td>-1.432808</td>\n",
       "      <td>-1.322319</td>\n",
       "      <td>-1.439375</td>\n",
       "      <td>-1.162818</td>\n",
       "      <td>-1.445319</td>\n",
       "      <td>-1.301703</td>\n",
       "      <td>-1.422016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055989</td>\n",
       "      <td>-0.110715</td>\n",
       "      <td>-0.074154</td>\n",
       "      <td>-0.094165</td>\n",
       "      <td>-0.052363</td>\n",
       "      <td>-0.054206</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.593334</td>\n",
       "      <td>-0.876299</td>\n",
       "      <td>-1.236196</td>\n",
       "      <td>-1.158298</td>\n",
       "      <td>-0.856437</td>\n",
       "      <td>-1.091651</td>\n",
       "      <td>-1.036564</td>\n",
       "      <td>-1.184168</td>\n",
       "      <td>-1.255921</td>\n",
       "      <td>-1.228438</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055989</td>\n",
       "      <td>-0.110715</td>\n",
       "      <td>-0.074154</td>\n",
       "      <td>-0.094165</td>\n",
       "      <td>-0.052363</td>\n",
       "      <td>-0.054206</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.253223</td>\n",
       "      <td>-0.663164</td>\n",
       "      <td>-1.055038</td>\n",
       "      <td>-0.922501</td>\n",
       "      <td>-0.554242</td>\n",
       "      <td>-0.826139</td>\n",
       "      <td>-0.405295</td>\n",
       "      <td>-1.040580</td>\n",
       "      <td>-1.111250</td>\n",
       "      <td>-1.082030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055989</td>\n",
       "      <td>-0.110715</td>\n",
       "      <td>-0.074154</td>\n",
       "      <td>-0.094165</td>\n",
       "      <td>-0.052363</td>\n",
       "      <td>-0.054206</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.086888</td>\n",
       "      <td>-0.387864</td>\n",
       "      <td>-1.027864</td>\n",
       "      <td>-0.772048</td>\n",
       "      <td>-0.059579</td>\n",
       "      <td>-0.554536</td>\n",
       "      <td>-0.405295</td>\n",
       "      <td>-0.970581</td>\n",
       "      <td>-0.924460</td>\n",
       "      <td>-0.971765</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055989</td>\n",
       "      <td>-0.110715</td>\n",
       "      <td>-0.074154</td>\n",
       "      <td>-0.094165</td>\n",
       "      <td>-0.052363</td>\n",
       "      <td>-0.054206</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 447 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wins Tally  PF Tally  PA Tally  OPassY Tally  ORushY Tally  OTotYd Tally  \\\n",
       "0   -1.273555 -1.515705 -1.544165     -1.571823     -1.498599     -1.595272   \n",
       "1   -0.933444 -1.240405 -1.390180     -1.432808     -1.322319     -1.439375   \n",
       "2   -0.593334 -0.876299 -1.236196     -1.158298     -0.856437     -1.091651   \n",
       "3   -0.253223 -0.663164 -1.055038     -0.922501     -0.554242     -0.826139   \n",
       "4    0.086888 -0.387864 -1.027864     -0.772048     -0.059579     -0.554536   \n",
       "\n",
       "   TO_lost Tally  DPassY Tally  DRushY Tally  DTotYd Tally  ...  \\\n",
       "0      -1.415325     -1.601472     -1.523287     -1.602728  ...   \n",
       "1      -1.162818     -1.445319     -1.301703     -1.422016  ...   \n",
       "2      -1.036564     -1.184168     -1.255921     -1.228438  ...   \n",
       "3      -0.405295     -1.040580     -1.111250     -1.082030  ...   \n",
       "4      -0.405295     -0.970581     -0.924460     -0.971765  ...   \n",
       "\n",
       "   QB_Tom Savage  QB_Tony Romo  QB_Trevor Siemian  QB_Tyrod Taylor  \\\n",
       "0      -0.055989     -0.110715          -0.074154        -0.094165   \n",
       "1      -0.055989     -0.110715          -0.074154        -0.094165   \n",
       "2      -0.055989     -0.110715          -0.074154        -0.094165   \n",
       "3      -0.055989     -0.110715          -0.074154        -0.094165   \n",
       "4      -0.055989     -0.110715          -0.074154        -0.094165   \n",
       "\n",
       "   QB_Vince Young  QB_Zach Mettenberger  Results  Week  Home  After_Bye  \n",
       "0       -0.052363             -0.054206      1.0     1   0.0          0  \n",
       "1       -0.052363             -0.054206      1.0     2   0.0          0  \n",
       "2       -0.052363             -0.054206      1.0     3   1.0          0  \n",
       "3       -0.052363             -0.054206      1.0     5   1.0          1  \n",
       "4       -0.052363             -0.054206      1.0     6   0.0          0  \n",
       "\n",
       "[5 rows x 447 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with the scaled data\n",
    "transformed_scaled_data = pd.DataFrame(scaled_data, columns=encoded_df.columns)\n",
    "transformed_scaled_data = transformed_scaled_data.drop(columns=['Results', 'Week', 'Home', 'After_Bye'])\n",
    "transformed_scaled_data['Results'] = encoded_df['Results']\n",
    "transformed_scaled_data['Week'] = encoded_df['Week']\n",
    "transformed_scaled_data['Home'] = encoded_df['Home']\n",
    "transformed_scaled_data['After_Bye'] = encoded_df['After_Bye']\n",
    "transformed_scaled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_scaled_data = transformed_scaled_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 100)               44700     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 75)                7575      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 50)                3800      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 57,671\n",
      "Trainable params: 57,671\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.6783 - accuracy: 0.5677\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.6326\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.6622\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 0.6779\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7068\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7091\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7362\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7617\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7719\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7922\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3961 - accuracy: 0.8094\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8346\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8516\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2846 - accuracy: 0.8664\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.8760\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.8992\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 0.9083\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1938 - accuracy: 0.9203\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1696 - accuracy: 0.9266\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1511 - accuracy: 0.9370\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1367 - accuracy: 0.9432\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.9466\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1102 - accuracy: 0.9544\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.9503\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1053 - accuracy: 0.9557\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.9594\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1013 - accuracy: 0.9563\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0837 - accuracy: 0.9669\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0895 - accuracy: 0.9633\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0919 - accuracy: 0.9638\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0869 - accuracy: 0.9667\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9677\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0897 - accuracy: 0.9625\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.9740\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0814 - accuracy: 0.9716\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9716\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9711\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9755\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.9737\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.9716\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.9729\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.9792\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.9747\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.9745\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.9729\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.9766\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.9784\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.9794\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9810\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.9823\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9828\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0500 - accuracy: 0.9805\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9768\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0930 - accuracy: 0.9680\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1034 - accuracy: 0.9646\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0735 - accuracy: 0.9768\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9779\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0738 - accuracy: 0.9727\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.9779\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 0.9875\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9867\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9841\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 0.9831\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.9805\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9823\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0519 - accuracy: 0.9818\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.9870\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.9810\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9797\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.9747\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9695\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9789\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0428 - accuracy: 0.9849\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.9865\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9885\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9859\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.9859\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0250 - accuracy: 0.9891\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9880\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9878\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.9849\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0398 - accuracy: 0.9841\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9768\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.9828\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9826\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9810\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9810\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9833\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9857\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.9888\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9914\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.9911\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 0.9909\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 0.9909\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9893\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9891\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.9849\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9818\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.9784\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0805 - accuracy: 0.9732\n"
     ]
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = transformed_scaled_data[\"Results\"].values\n",
    "X = transformed_scaled_data.drop([\"Results\"],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  100\n",
    "hidden_nodes_layer2 =  75\n",
    "hidden_nodes_layer3 =  50\n",
    "hidden_nodes_layer4 =  25\n",
    "hidden_nodes_layer5 =  10\n",
    "hidden_nodes_layer6 =  5\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add hidden layers\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer5, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer6, activation=\"relu\"))\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "# Check the structure of the model\n",
    "nn.summary()\n",
    "\n",
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 - 0s - loss: 2.5101 - accuracy: 0.5656\n",
      "Loss: 2.510105848312378, Accuracy: 0.565625011920929\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistic regression model accuracy: 0.601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amnic\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = transformed_scaled_data[\"Results\"].values\n",
    "X = transformed_scaled_data.drop([\"Results\"],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Define the logistic regression model\n",
    "log_classifier = LogisticRegression(solver=\"lbfgs\",max_iter=200)\n",
    "\n",
    "# Train the model\n",
    "log_classifier.fit(X_train,y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = log_classifier.predict(X_test)\n",
    "print(f\" Logistic regression model accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 8)                 3576      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 5)                 45        \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 3,627\n",
      "Trainable params: 3,627\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.6982 - accuracy: 0.5552\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.6510 - accuracy: 0.6219\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.6321 - accuracy: 0.6458\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6594\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.6057 - accuracy: 0.6693\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.6727\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.6763\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.5776 - accuracy: 0.6891\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.6927\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.6990\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7039\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7070\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7172\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7154\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7211\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7312\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7221\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7310\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7302\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7372\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7406\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7406\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7461\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7466\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7513\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7552\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7591\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7542\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7615\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7615\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7643\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7648\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7698\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7768\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7786\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7779\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7831\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7810\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7818\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7815\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7909\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7964\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7872\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7922\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7964\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7956\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8013\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.7997\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.4105 - accuracy: 0.8008\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.4077 - accuracy: 0.8034\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8042\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8065\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.3976 - accuracy: 0.8099\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8109\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8115\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.3947 - accuracy: 0.8130\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8122\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8125\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8167\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8151\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.3822 - accuracy: 0.8164\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8188\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8195\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8201\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8167\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8258\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8250\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8255\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8242\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8289\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8281\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8326\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8352\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8255\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8326\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.3559 - accuracy: 0.8323\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8315\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8378\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8349\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8367\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3506 - accuracy: 0.8333\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.8378\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8411\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3444 - accuracy: 0.8388\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8409\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8396\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8391\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8453\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8396\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8422\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3377 - accuracy: 0.8422\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8404\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8461\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8456\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8448\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8424\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8432\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8422\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8435\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8490\n"
     ]
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = transformed_scaled_data[\"Results\"].values\n",
    "X = transformed_scaled_data.drop([\"Results\"],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  8\n",
    "hidden_nodes_layer2 =  5\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add hidden layers\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "# Check the structure of the model\n",
    "nn.summary()\n",
    "\n",
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 - 0s - loss: 1.3151 - accuracy: 0.5805\n",
      "Loss: 1.315056562423706, Accuracy: 0.5804687738418579\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SVM model accuracy: 0.565\n"
     ]
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = transformed_scaled_data[\"Results\"].values\n",
    "X = transformed_scaled_data.drop([\"Results\"],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Create the SVM model\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "# Train the model\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = svm.predict(X_test_scaled)\n",
    "print(f\" SVM model accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Random forest predictive accuracy: 0.613\n",
      " Random forest predictive accuracy: 0.613\n"
     ]
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = transformed_scaled_data[\"Results\"].values\n",
    "X = transformed_scaled_data.drop([\"Results\"],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Create a random forest classifier.\n",
    "rf_model = RandomForestClassifier(n_estimators=128, random_state=78)\n",
    "\n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weekly Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "week1 = pd.read_csv('Resources/weekly_csvs/week1.csv')\n",
    "week2 = pd.read_csv('Resources/weekly_csvs/week2.csv')\n",
    "week3 = pd.read_csv('Resources/weekly_csvs/week3.csv')\n",
    "week4 = pd.read_csv('Resources/weekly_csvs/week4.csv')\n",
    "week5 = pd.read_csv('Resources/weekly_csvs/week5.csv')\n",
    "week6 = pd.read_csv('Resources/weekly_csvs/week6.csv')\n",
    "week7 = pd.read_csv('Resources/weekly_csvs/week7.csv')\n",
    "week8 = pd.read_csv('Resources/weekly_csvs/week8.csv')\n",
    "week9 = pd.read_csv('Resources/weekly_csvs/week9.csv')\n",
    "week10 = pd.read_csv('Resources/weekly_csvs/week10.csv')\n",
    "week11 = pd.read_csv('Resources/weekly_csvs/week11.csv')\n",
    "week12 = pd.read_csv('Resources/weekly_csvs/week12.csv')\n",
    "week13 = pd.read_csv('Resources/weekly_csvs/week13.csv')\n",
    "week14 = pd.read_csv('Resources/weekly_csvs/week14.csv')\n",
    "week15 = pd.read_csv('Resources/weekly_csvs/week15.csv')\n",
    "week16 = pd.read_csv('Resources/weekly_csvs/week16.csv')\n",
    "week17 = pd.read_csv('Resources/weekly_csvs/week17.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "week1 = week1.drop(columns='Unnamed: 0')\n",
    "week2 = week2.drop(columns='Unnamed: 0')\n",
    "week3 = week3.drop(columns='Unnamed: 0')\n",
    "week4 = week4.drop(columns='Unnamed: 0')\n",
    "week5 = week5.drop(columns='Unnamed: 0')\n",
    "week6 = week6.drop(columns='Unnamed: 0')\n",
    "week7 = week7.drop(columns='Unnamed: 0')\n",
    "week8 = week8.drop(columns='Unnamed: 0')\n",
    "week9 = week9.drop(columns='Unnamed: 0')\n",
    "week10 = week10.drop(columns='Unnamed: 0')\n",
    "week11 = week11.drop(columns='Unnamed: 0')\n",
    "week12 = week12.drop(columns='Unnamed: 0')\n",
    "week13 = week13.drop(columns='Unnamed: 0')\n",
    "week14 = week14.drop(columns='Unnamed: 0')\n",
    "week15 = week15.drop(columns='Unnamed: 0')\n",
    "week16 = week16.drop(columns='Unnamed: 0')\n",
    "week17 = week17.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 1 - 58.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wins Tally</th>\n",
       "      <th>PF Tally</th>\n",
       "      <th>PA Tally</th>\n",
       "      <th>OPassY Tally</th>\n",
       "      <th>ORushY Tally</th>\n",
       "      <th>OTotYd Tally</th>\n",
       "      <th>TO_lost Tally</th>\n",
       "      <th>DPassY Tally</th>\n",
       "      <th>DRushY Tally</th>\n",
       "      <th>DTotYd Tally</th>\n",
       "      <th>...</th>\n",
       "      <th>QB_Tony Romo</th>\n",
       "      <th>QB_Trevor Siemian</th>\n",
       "      <th>QB_Tyrod Taylor</th>\n",
       "      <th>QB_Vince Young</th>\n",
       "      <th>QB_Zach Mettenberger</th>\n",
       "      <th>Year</th>\n",
       "      <th>Results</th>\n",
       "      <th>Week</th>\n",
       "      <th>Home</th>\n",
       "      <th>After_Bye</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112867</td>\n",
       "      <td>-0.09759</td>\n",
       "      <td>-0.09759</td>\n",
       "      <td>-0.056166</td>\n",
       "      <td>-0.056166</td>\n",
       "      <td>2019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112867</td>\n",
       "      <td>-0.09759</td>\n",
       "      <td>-0.09759</td>\n",
       "      <td>-0.056166</td>\n",
       "      <td>-0.056166</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112867</td>\n",
       "      <td>-0.09759</td>\n",
       "      <td>-0.09759</td>\n",
       "      <td>-0.056166</td>\n",
       "      <td>-0.056166</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112867</td>\n",
       "      <td>-0.09759</td>\n",
       "      <td>-0.09759</td>\n",
       "      <td>-0.056166</td>\n",
       "      <td>-0.056166</td>\n",
       "      <td>2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112867</td>\n",
       "      <td>-0.09759</td>\n",
       "      <td>-0.09759</td>\n",
       "      <td>-0.056166</td>\n",
       "      <td>-0.056166</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 449 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wins Tally  PF Tally  PA Tally  OPassY Tally  ORushY Tally  OTotYd Tally  \\\n",
       "0         0.0       0.0       0.0           0.0           0.0           0.0   \n",
       "1         0.0       0.0       0.0           0.0           0.0           0.0   \n",
       "2         0.0       0.0       0.0           0.0           0.0           0.0   \n",
       "3         0.0       0.0       0.0           0.0           0.0           0.0   \n",
       "4         0.0       0.0       0.0           0.0           0.0           0.0   \n",
       "\n",
       "   TO_lost Tally  DPassY Tally  DRushY Tally  DTotYd Tally  ...  QB_Tony Romo  \\\n",
       "0            0.0           0.0           0.0           0.0  ...     -0.112867   \n",
       "1            0.0           0.0           0.0           0.0  ...     -0.112867   \n",
       "2            0.0           0.0           0.0           0.0  ...     -0.112867   \n",
       "3            0.0           0.0           0.0           0.0  ...     -0.112867   \n",
       "4            0.0           0.0           0.0           0.0  ...     -0.112867   \n",
       "\n",
       "   QB_Trevor Siemian  QB_Tyrod Taylor  QB_Vince Young  QB_Zach Mettenberger  \\\n",
       "0           -0.09759         -0.09759       -0.056166             -0.056166   \n",
       "1           -0.09759         -0.09759       -0.056166             -0.056166   \n",
       "2           -0.09759         -0.09759       -0.056166             -0.056166   \n",
       "3           -0.09759         -0.09759       -0.056166             -0.056166   \n",
       "4           -0.09759         -0.09759       -0.056166             -0.056166   \n",
       "\n",
       "   Year  Results  Week  Home  After_Bye  \n",
       "0  2019      1.0     1   0.0          0  \n",
       "1  2018      0.0     1   0.0          0  \n",
       "2  2017      0.0     1   1.0          0  \n",
       "3  2016      1.0     1   1.0          0  \n",
       "4  2015      1.0     1   1.0          0  \n",
       "\n",
       "[5 rows x 449 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "encoded_df = encode_merge(week1, cat_list=cat_columns(week1))\n",
    "\n",
    "# Fit the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(encoded_df)\n",
    "scaled_data = scaler.transform(encoded_df)\n",
    "\n",
    "# Create a DataFrame with the scaled data\n",
    "transformed_scaled_data = pd.DataFrame(scaled_data, columns=encoded_df.columns)\n",
    "transformed_scaled_data = transformed_scaled_data.drop(columns=['Results', 'Week', 'Home', 'After_Bye', 'Year'])\n",
    "transformed_scaled_data['Year'] = encoded_df['Year']\n",
    "transformed_scaled_data['Results'] = encoded_df['Results']\n",
    "transformed_scaled_data['Week'] = encoded_df['Week']\n",
    "transformed_scaled_data['Home'] = encoded_df['Home']\n",
    "transformed_scaled_data['After_Bye'] = encoded_df['After_Bye']\n",
    "transformed_scaled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_scaled_data = transformed_scaled_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 300)               134700    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 225)               67725     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 150)               33900     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 75)                7575      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 25)                1900      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 260,926\n",
      "Trainable params: 260,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9449 - accuracy: 0.5210\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.9192 - accuracy: 0.4874\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.0464 - accuracy: 0.5168\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.8679 - accuracy: 0.5378\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.9617 - accuracy: 0.5210\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.9035 - accuracy: 0.4706\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.2676 - accuracy: 0.5294\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.8333 - accuracy: 0.5336\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.9085 - accuracy: 0.5168\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7274 - accuracy: 0.6134\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6022 - accuracy: 0.7185\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6991 - accuracy: 0.6176\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.0959 - accuracy: 0.5210\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7343 - accuracy: 0.5630\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.6261\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6207 - accuracy: 0.6303\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5651 - accuracy: 0.6765\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7353\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.8025\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.7143\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7983\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8529\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3743 - accuracy: 0.8992\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3579 - accuracy: 0.8655\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.7941\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3321 - accuracy: 0.8782\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3273 - accuracy: 0.8824\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.8697\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4028 - accuracy: 0.7983\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.7899\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.8613\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7857\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3416 - accuracy: 0.8487\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.7059\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.7815\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.8655\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2581 - accuracy: 0.8908\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2308 - accuracy: 0.9118\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2881 - accuracy: 0.8782\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2131 - accuracy: 0.9244\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2109 - accuracy: 0.9202\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.8908\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2206 - accuracy: 0.8992\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3423 - accuracy: 0.8361\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2303 - accuracy: 0.8950\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2934 - accuracy: 0.8655\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8109\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7983\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2424 - accuracy: 0.8908\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2429 - accuracy: 0.8950\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.8739\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.9202\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2518 - accuracy: 0.8950\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8697\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1927 - accuracy: 0.9034\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1693 - accuracy: 0.9244\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1839 - accuracy: 0.9244\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1436 - accuracy: 0.9328\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1730 - accuracy: 0.9286\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.8992\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2776 - accuracy: 0.8908\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1598 - accuracy: 0.9370\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1331 - accuracy: 0.9412\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1738 - accuracy: 0.9160\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.9160\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1705 - accuracy: 0.9454\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1742 - accuracy: 0.9160\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.9496\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1437 - accuracy: 0.9412\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.8866\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2766 - accuracy: 0.8655\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.8824\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3940 - accuracy: 0.8445\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.8277\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.9034\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9370\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1809 - accuracy: 0.9160\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1471 - accuracy: 0.9244\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9454\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2210 - accuracy: 0.9118\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3057 - accuracy: 0.8655\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.8193\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1452 - accuracy: 0.9454\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1455 - accuracy: 0.9244\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2226 - accuracy: 0.9034\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3479 - accuracy: 0.8655\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7795 - accuracy: 0.7437\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.7731\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2741 - accuracy: 0.8655\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2388 - accuracy: 0.8824\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1488 - accuracy: 0.9412\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2030 - accuracy: 0.9160\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1388 - accuracy: 0.9286\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1279 - accuracy: 0.9412\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1074 - accuracy: 0.9496\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1153 - accuracy: 0.9370\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0925 - accuracy: 0.9538\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1069 - accuracy: 0.9538\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1120 - accuracy: 0.9496\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0838 - accuracy: 0.9706\n"
     ]
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = transformed_scaled_data[\"Results\"].values\n",
    "X = transformed_scaled_data.drop([\"Results\"],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  300\n",
    "hidden_nodes_layer2 =  225\n",
    "hidden_nodes_layer3 =  150\n",
    "hidden_nodes_layer4 =  100\n",
    "hidden_nodes_layer5 =  75\n",
    "hidden_nodes_layer6 =  25\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add hidden layers\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer5, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer6, activation=\"relu\"))\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "# Check the structure of the model\n",
    "nn.summary()\n",
    "\n",
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 1.4851 - accuracy: 0.5875\n",
      "Loss: 1.4850810766220093, Accuracy: 0.5874999761581421\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 17 - 61.3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "encoded_df = encode_merge(week17, cat_list=cat_columns(week17))\n",
    "\n",
    "# Fit the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(encoded_df)\n",
    "scaled_data = scaler.transform(encoded_df)\n",
    "\n",
    "# Create a DataFrame with the scaled data\n",
    "transformed_scaled_data = pd.DataFrame(scaled_data, columns=encoded_df.columns)\n",
    "transformed_scaled_data = transformed_scaled_data.drop(columns=['Results', 'Week', 'Home', 'After_Bye', 'Year'])\n",
    "transformed_scaled_data['Year'] = encoded_df['Year']\n",
    "transformed_scaled_data['Results'] = encoded_df['Results']\n",
    "transformed_scaled_data['Week'] = encoded_df['Week']\n",
    "transformed_scaled_data['Home'] = encoded_df['Home']\n",
    "transformed_scaled_data['After_Bye'] = encoded_df['After_Bye']\n",
    "\n",
    "transformed_scaled_data = transformed_scaled_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 300)               132600    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 225)               67725     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 150)               33900     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 75)                7575      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 25)                1900      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 258,826\n",
      "Trainable params: 258,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10.5323 - accuracy: 0.4917\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.4487 - accuracy: 0.4750\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2221 - accuracy: 0.4500\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.2389 - accuracy: 0.4500\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.2839 - accuracy: 0.4250\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.1712 - accuracy: 0.5375\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1429 - accuracy: 0.5667\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.9395 - accuracy: 0.4625\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7152 - accuracy: 0.5625\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6861 - accuracy: 0.5750\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.5833\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6989 - accuracy: 0.5833\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.8495 - accuracy: 0.5625\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.9672 - accuracy: 0.4625\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.8266 - accuracy: 0.5375\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5577 - accuracy: 0.7000\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5496 - accuracy: 0.7375\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.6958\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.8125\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.6708\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7083\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7958\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8875\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7708\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7476 - accuracy: 0.6083\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.6792\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6651 - accuracy: 0.6833\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6681 - accuracy: 0.6875\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3882 - accuracy: 0.8292\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8167\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3328 - accuracy: 0.8792\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3364 - accuracy: 0.8500\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3858 - accuracy: 0.8125\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3316 - accuracy: 0.8250\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8292\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2830 - accuracy: 0.8875\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3026 - accuracy: 0.8667\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2927 - accuracy: 0.8792\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2744 - accuracy: 0.8792\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3634 - accuracy: 0.8250\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7625\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3715 - accuracy: 0.8083\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2555 - accuracy: 0.8875\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2891 - accuracy: 0.8500\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2706 - accuracy: 0.8958\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3399 - accuracy: 0.8500\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3989 - accuracy: 0.8208\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2443 - accuracy: 0.8875\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2129 - accuracy: 0.9208\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2585 - accuracy: 0.8875\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3279 - accuracy: 0.8542\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3243 - accuracy: 0.8417\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.8000\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3075 - accuracy: 0.8625\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2527 - accuracy: 0.9000\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2940 - accuracy: 0.8667\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2345 - accuracy: 0.8875\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1833 - accuracy: 0.9042\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1910 - accuracy: 0.9000\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2531 - accuracy: 0.8958\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1798 - accuracy: 0.9375\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2799 - accuracy: 0.8750\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8250\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.7833\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3845 - accuracy: 0.8208\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2296 - accuracy: 0.9000\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1687 - accuracy: 0.9208\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1480 - accuracy: 0.9500\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1634 - accuracy: 0.9333\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2046 - accuracy: 0.9083\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1779 - accuracy: 0.9125\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1882 - accuracy: 0.9167\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1847 - accuracy: 0.9000\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1956 - accuracy: 0.9333\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1270 - accuracy: 0.9500\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1322 - accuracy: 0.9417\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1370 - accuracy: 0.9458\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1985 - accuracy: 0.9083\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3390 - accuracy: 0.8625\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2117 - accuracy: 0.9167\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2440 - accuracy: 0.8917\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5017 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8542\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2226 - accuracy: 0.9125\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1728 - accuracy: 0.9292\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1686 - accuracy: 0.9333\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1681 - accuracy: 0.9250\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1364 - accuracy: 0.9375\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1232 - accuracy: 0.9458\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1493 - accuracy: 0.9333\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2432 - accuracy: 0.9042\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2995 - accuracy: 0.8917\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1939 - accuracy: 0.9125\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1160 - accuracy: 0.9583\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1100 - accuracy: 0.9583\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1889 - accuracy: 0.9125\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2034 - accuracy: 0.9125\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1174 - accuracy: 0.9583\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1644 - accuracy: 0.9208\n"
     ]
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = transformed_scaled_data[\"Results\"].values\n",
    "X = transformed_scaled_data.drop([\"Results\"],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  300\n",
    "hidden_nodes_layer2 =  225\n",
    "hidden_nodes_layer3 =  150\n",
    "hidden_nodes_layer4 =  100\n",
    "hidden_nodes_layer5 =  75\n",
    "hidden_nodes_layer6 =  25\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add hidden layers\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer5, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer6, activation=\"relu\"))\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "# Check the structure of the model\n",
    "nn.summary()\n",
    "\n",
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000023B9DFB99D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 - 0s - loss: 1.4408 - accuracy: 0.6000\n",
      "Loss: 1.4408079385757446, Accuracy: 0.6000000238418579\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Random forest predictive accuracy: 0.613\n"
     ]
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = transformed_scaled_data[\"Results\"].values\n",
    "X = transformed_scaled_data.drop([\"Results\"],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Create a random forest classifier.\n",
    "rf_model = RandomForestClassifier(n_estimators=128, random_state=78)\n",
    "\n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
